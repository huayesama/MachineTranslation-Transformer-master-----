{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "R619Z2Qy7IrX"
   },
   "outputs": [],
   "source": [
    "#挂载到谷歌云盘，本地跑不用挂载\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!pip install keras-transformer\n",
    "!pwd\n",
    "!ls \"/content/drive/My Drive/Colab Notebooks/middle_data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3171,
     "status": "ok",
     "timestamp": 1588303923502,
     "user": {
      "displayName": "Jayee Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdF_nXQgSlUtrprqDLXzf9Kn59RlonvtGF4nHZ=s64",
      "userId": "08268369137892915441"
     },
     "user_tz": -480
    },
    "id": "2PLmOwOK6Toh",
    "outputId": "dad250e0-757c-4d06-d9ff-697bde7150bd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import operator\n",
    "from keras_transformer import get_model, decode\n",
    "# main_path = '/content/drive/My Drive/Colab Notebooks/'    #Google Colab FilePath\n",
    "# path = main_path + 'middle_data/'\n",
    "path = 'middle_data/'\n",
    "with open(path + 'encode_input.pkl', 'rb') as f:\n",
    "    encode_input = pickle.load(f)\n",
    "with open(path + 'decode_input.pkl', 'rb') as f:\n",
    "    decode_input = pickle.load(f)\n",
    "with open(path + 'decode_output.pkl', 'rb') as f:\n",
    "    decode_output = pickle.load(f)\n",
    "with open(path + 'source_token_dict.pkl', 'rb') as f:\n",
    "    source_token_dict = pickle.load(f)\n",
    "with open(path + 'target_token_dict.pkl', 'rb') as f:\n",
    "    target_token_dict = pickle.load(f)\n",
    "with open(path + 'source_tokens.pkl', 'rb') as f:\n",
    "    source_tokens = pickle.load(f)\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2752,
     "status": "ok",
     "timestamp": 1588303929770,
     "user": {
      "displayName": "Jayee Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdF_nXQgSlUtrprqDLXzf9Kn59RlonvtGF4nHZ=s64",
      "userId": "08268369137892915441"
     },
     "user_tz": -480
    },
    "id": "em3y9E2S6Too",
    "outputId": "71c49f8b-a654-46c4-d381-76495a22b272"
   },
   "outputs": [],
   "source": [
    "print(len(source_token_dict))\n",
    "print(len(target_token_dict))\n",
    "print(len(encode_input))\n",
    "# 构建模型\n",
    "model = get_model(\n",
    "    token_num=max(len(source_token_dict), len(target_token_dict)),\n",
    "    embed_dim=64,\n",
    "    encoder_num=2,\n",
    "    decoder_num=2,\n",
    "    head_num=4,\n",
    "    hidden_dim=256,\n",
    "    dropout_rate=0.05,\n",
    "    use_same_embed=False,  # 不同语言需要使用不同的词嵌入\n",
    ")\n",
    "model.compile('adam', 'sparse_categorical_crossentropy')\n",
    "# model.summary()\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "collapsed": true,
    "executionInfo": {
     "elapsed": 2704582,
     "status": "ok",
     "timestamp": 1588306654812,
     "user": {
      "displayName": "Jayee Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdF_nXQgSlUtrprqDLXzf9Kn59RlonvtGF4nHZ=s64",
      "userId": "08268369137892915441"
     },
     "user_tz": -480
    },
    "id": "bezIJiRX6Tox",
    "outputId": "a9eda80b-c48b-402d-f43f-72252a193f5d"
   },
   "outputs": [],
   "source": [
    "#训练模型\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n",
    "filepath = path + \"models/W-\" + \"-{epoch:3d}-{loss:.4f}-.h5\"\n",
    "checkpoint = ModelCheckpoint(filepath,\n",
    "                    monitor='loss',\n",
    "                    verbose=1,\n",
    "                    save_best_only=True,\n",
    "                    mode='min',\n",
    "                    save_freq='epoch',\n",
    "                    )\n",
    "reduce_lr = ReduceLROnPlateau(monitor='loss', \n",
    "                    factor=0.2, \n",
    "                    patience=2, \n",
    "                    verbose=1, \n",
    "                    mode='min', \n",
    "                    min_delta=0.0001, \n",
    "                    cooldown=0, \n",
    "                    min_lr=0\n",
    "                    )\n",
    "callbacks_list = [checkpoint, reduce_lr]\n",
    "model.fit(\n",
    "    x=[np.array(encode_input[:20000]), np.array(decode_input[:20000])],\n",
    "    y=np.array(decode_output[:20000]),\n",
    "    epochs=100,\n",
    "    batch_size=64, \n",
    "    verbose=1,\n",
    "    callbacks=callbacks_list, \n",
    "    # class_weight=None, \n",
    "    # max_queue_size=5, \n",
    "#    workers=1, \n",
    "#    use_multiprocessing=False,\n",
    "    # shuffle=False,\n",
    "#    initial_epoch=initial_epoch_\n",
    "    )\n",
    "# model.save(main_path+'modles/model.h5')a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 8343,
     "status": "ok",
     "timestamp": 1588309168109,
     "user": {
      "displayName": "Jayee Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdF_nXQgSlUtrprqDLXzf9Kn59RlonvtGF4nHZ=s64",
      "userId": "08268369137892915441"
     },
     "user_tz": -480
    },
    "id": "DIPdi5jJ6To3",
    "outputId": "fb4ff73c-2b7b-409d-88fa-ef1a5581b159"
   },
   "outputs": [],
   "source": [
    "#加载模型\n",
    "model.load_weights('model\\W-- 99-0.0070-.h5')\n",
    "target_token_dict_inv = {v: k for k, v in target_token_dict.items()}\n",
    "print('Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 155461,
     "status": "ok",
     "timestamp": 1588309337115,
     "user": {
      "displayName": "Jayee Wong",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhdF_nXQgSlUtrprqDLXzf9Kn59RlonvtGF4nHZ=s64",
      "userId": "08268369137892915441"
     },
     "user_tz": -480
    },
    "id": "waCFmuVtjRn5",
    "outputId": "4f15a6a7-e0cb-4857-dcaa-8759a706d86d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['']\n",
      "['<START>', '', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "That's .\n",
      "['']\n",
      "['<START>', '', '<END>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>', '<PAD>']\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "1/1 [==============================] - 0s 35ms/step\n",
      "That's .\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 40\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mmap\u001b[39m(\u001b[38;5;28;01mlambda\u001b[39;00m x: target_token_dict_inv[x], decoded[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m])))\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m---> 40\u001b[0m     seq \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     41\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m seq \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mx\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m     42\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32my:\\anaconda\\envs\\translate\\lib\\site-packages\\ipykernel\\kernelbase.py:1282\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1280\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1281\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1282\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1283\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1284\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1285\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1286\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1287\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32my:\\anaconda\\envs\\translate\\lib\\site-packages\\ipykernel\\kernelbase.py:1325\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1322\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1323\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1324\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1325\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1326\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1327\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import sequence\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import jieba\n",
    "import requests\n",
    "\n",
    "def get_input(seq):\n",
    "    seq = ' '.join(jieba.lcut(seq, cut_all=False))\n",
    "    # seq = ' '.join(seq)\n",
    "    seq = seq.split(' ')\n",
    "    print(seq)\n",
    "    seq = ['<START>'] + seq + ['<END>']\n",
    "    seq = seq + ['<PAD>'] * (34 - len(seq))\n",
    "    print(seq)\n",
    "    for x in seq:\n",
    "        try:\n",
    "            source_token_dict[x]\n",
    "        except KeyError:\n",
    "            flag=False\n",
    "            break\n",
    "        else:\n",
    "            flag=True\n",
    "    if(flag):\n",
    "        seq = [source_token_dict[x] for x in seq]\n",
    "    return flag, seq\n",
    "def get_ans(seq):\n",
    "    decoded = decode(\n",
    "    model,\n",
    "    [seq],\n",
    "    start_token=target_token_dict['<START>'],\n",
    "    end_token=target_token_dict['<END>'],\n",
    "    pad_token=target_token_dict['<PAD>'],\n",
    "    # top_k=8,\n",
    "    # temperature=1.0,\n",
    "  )\n",
    "    print(' '.join(map(lambda x: target_token_dict_inv[x], decoded[0][1:-1])))\n",
    "\n",
    "while True:\n",
    "    seq = input()\n",
    "    if seq == 'x':\n",
    "        break\n",
    "    flag, seq = get_input(seq)\n",
    "    if(flag):\n",
    "        get_ans(seq)\n",
    "    else:\n",
    "        print('听不懂呢。')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GlYO_CK9tLYE"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "train.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "translate",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.22"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
